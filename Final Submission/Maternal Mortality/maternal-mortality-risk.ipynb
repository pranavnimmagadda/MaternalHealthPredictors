{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12069575,"sourceType":"datasetVersion","datasetId":7597211}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, precision_score, recall_score\nimport time\nimport warnings\nimport pyarrow.parquet as pq\nwarnings.filterwarnings('ignore')\n\ndata_path = '/kaggle/input/fullfinal/telangana_data_with_features_and_targets (1).parquet'\nflag_map = {\n    'Y': 1, 'YES': 1, 'Yes': 1, 'y': 1, 'yes': 1,\n    'N': 0, 'NO': 0, 'No': 0, 'n': 0, 'no': 0,\n    None: np.nan, 'None': np.nan, '': np.nan, 'nan': np.nan\n}\n\ndef prepare_data_for_targets(data_path, flag_map, batch_size=10000):\n    \"\"\"Load and preprocess data from Parquet file in batches.\"\"\"\n    # Initialize an empty list to store processed chunks\n    processed_chunks = []\n    \n    # Define required and numeric columns\n    required_cols = ['MOTHER_ID', 'GRAVIDA']\n    numeric_cols = ['AGE', 'AGE_preg', 'AGE_final', 'GRAVIDA', 'PARITY', 'ABORTIONS', 'TOTAL_ANC_VISITS',\n                    'HEMOGLOBIN_mean', 'HEMOGLOBIN_min', 'WEIGHT_max', 'HEIGHT',\n                    'PHQ_SCORE_max', 'GAD_SCORE_max', 'WEIGHT_last', 'WEIGHT_first',\n                    'NO_OF_WEEKS_max', 'WEIGHT_min', 'WEIGHT_mean']\n    \n    # Open Parquet file using pyarrow\n    parquet_file = pq.ParquetFile(data_path)\n    num_rows = parquet_file.metadata.num_rows\n    num_batches = (num_rows + batch_size - 1) // batch_size  # Ceiling division\n    \n    # Iterate through batches\n    for batch_idx in range(num_batches):\n        # Read a batch of rows\n        start_row = batch_idx * batch_size\n        end_row = min(start_row + batch_size, num_rows)\n        batch = parquet_file.read_row_group(batch_idx).to_pandas() if parquet_file.num_row_groups > batch_idx else pd.DataFrame()\n        \n        if batch.empty:\n            continue\n            \n        # Check for required columns\n        for col in required_cols:\n            if col not in batch.columns:\n                raise ValueError(f\"Required column {col} missing in data\")\n\n        # Debug: Check non-numeric values\n        for col in numeric_cols:\n            if col in batch.columns and batch[col].dtype == 'object':\n                non_numeric = batch[col][~batch[col].apply(lambda x: str(x).replace('.', '').isdigit() if pd.notna(x) else False)]\n                if not non_numeric.empty:\n                    print(f\"Non-numeric values in {col}: {non_numeric.unique()[:10]}\")\n\n        # Clean GRAVIDA specifically\n        if 'GRAVIDA' in batch.columns:\n            batch['GRAVIDA'] = batch['GRAVIDA'].replace('nan', np.nan)\n            batch['GRAVIDA'] = pd.to_numeric(batch['GRAVIDA'], errors='coerce')\n            # Replace NaN with median GRAVIDA (or 1 as default) within batch\n            if batch['GRAVIDA'].notna().any():\n                median_gravida = batch['GRAVIDA'].median()\n                if pd.isna(median_gravida):\n                    median_gravida = 1.0\n                batch['GRAVIDA'] = batch['GRAVIDA'].fillna(0)\n                print(f\"Filled {batch['GRAVIDA'].isna().sum()} GRAVIDA NaN values with 0 in batch\")\n\n        # Convert other numeric columns\n        for col in numeric_cols:\n            if col in batch.columns and col != 'GRAVIDA':\n                batch[col] = pd.to_numeric(batch[col], errors='coerce')\n\n        # Map flag columns\n        if 'IS_CHILD_DEATH' in batch.columns and batch['IS_CHILD_DEATH'].dtype == 'object':\n            batch['IS_CHILD_DEATH'] = batch['IS_CHILD_DEATH'].map(flag_map)\n        if 'IS_DEFECTIVE_BIRTH' in batch.columns and batch['IS_DEFECTIVE_BIRTH'].dtype == 'object':\n            batch['IS_DEFECTIVE_BIRTH'] = batch['IS_DEFECTIVE_BIRTH'].map(flag_map)\n\n        # Fill NaN for numeric columns\n        batch_numeric_cols = batch.select_dtypes(include=['float64', 'float32', 'int64', 'int32', 'int8']).columns\n        batch[batch_numeric_cols] = batch[batch_numeric_cols].fillna(0)\n\n        # Append processed batch\n        processed_chunks.append(batch)\n\n    # Concatenate all chunks\n    df = pd.concat(processed_chunks, ignore_index=True)\n    return df\n\n# Execute the function\ndf = prepare_data_for_targets(data_path, flag_map)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-17T09:15:51.271612Z","iopub.execute_input":"2025-06-17T09:15:51.271923Z","iopub.status.idle":"2025-06-17T09:16:17.987985Z","shell.execute_reply.started":"2025-06-17T09:15:51.271902Z","shell.execute_reply":"2025-06-17T09:16:17.987011Z"}},"outputs":[{"name":"stdout","text":"Non-numeric values in GRAVIDA: ['nan']\nFilled 0 GRAVIDA NaN values with 0 in batch\nFilled 0 GRAVIDA NaN values with 0 in batch\nFilled 0 GRAVIDA NaN values with 0 in batch\nFilled 0 GRAVIDA NaN values with 0 in batch\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\n\n# Define target column for maternal mortality\ntarget_columns = ['maternal_mortality_risk']\n\ndef create_stratified_sample(df, target_column, sample_size=2000000):\n    \"\"\"Create a stratified sample ensuring all critical cases for maternal mortality are included.\"\"\"\n    maternal_death_col = 'maternal_mortality_risk'\n    critical_cases = pd.DataFrame()\n    \n    # Prioritize maternal mortality cases\n    if maternal_death_col in df.columns:\n        maternal_deaths = df[df[maternal_death_col] == 1]\n        critical_cases = pd.concat([critical_cases, maternal_deaths])\n    \n    # Optionally include related critical cases (e.g., stillbirths or child deaths) if relevant\n    if 'stillbirth_risk' in df.columns:\n        stillbirths = df[df['stillbirth_risk'] == 1]\n        critical_cases = pd.concat([critical_cases, stillbirths])\n    if 'IS_CHILD_DEATH' in df.columns:\n        child_deaths = df[df['IS_CHILD_DEATH'] == 1]\n        critical_cases = pd.concat([critical_cases, child_deaths])\n    \n    critical_cases = critical_cases.drop_duplicates()\n    \n    remaining_size = sample_size - len(critical_cases)\n    \n    if remaining_size > 0:\n        other_cases = df[~df.index.isin(critical_cases.index)]\n        sampled_others = other_cases.sample(n=remaining_size, random_state=42)\n        final_sample = pd.concat([critical_cases, sampled_others])\n    else:\n        final_sample = critical_cases.sample(n=sample_size, random_state=42)\n    \n    return final_sample\n\n# Create sample for maternal mortality\nsample_df = create_stratified_sample(df, 'maternal_mortality_risk')\n\n# Define columns to exclude to prevent data leakage\nexclude_cols = [\n    # Targets & labels\n    'maternal_mortality_risk', 'stillbirth_risk', 'premature_birth_risk',\n    'birth_defect_risk', 'anc_dropout', 'high_risk_pregnancy',\n\n    # Derived risk scores and flags\n    'total_risk_factors', 'clinical_risk_score', 'risk_level', 'predicted_risk',\n    'total_missed_visits', 'age_risk_score', 'demographic_risk', 'anemia_risk_score',\n    'overall_risk_score',\n\n    # Identifiers\n    'MOTHER_ID', 'ANC_ID', 'CHILD_ID', 'unique_id', 'EID', 'UID_NUMBER',\n\n    # Delivery outcome or post-delivery info (leakage)\n    'WEIGHT_child_mean', 'DELIVERY_MODE', 'MATERNAL_OUTCOME', 'IS_DELIVERED',\n    'DELIVERY_OUTCOME', 'DATE_OF_DELIVERY', 'PLACE_OF_DELIVERY', 'DEL_TIME',\n    'DATE_OF_DISCHARGE', 'DISCHARGE_TIME', 'JSY_BENEFICIARY',\n    'IS_MOTHER_ALIVE', 'IS_CHILD_DEATH', 'CHILD_DEATH_DATE', 'CHILD_DEATH_REASON',\n    'DEFECT_HEALTH_CENTER', 'IS_DEFECTIVE_BIRTH', 'BIRTH_DEFECT_TYPE',\n    'BIRTH_DEFECT_SUBTYPE', 'DEFECT_SUBTYPE_OTHER', 'DEFECT_TYPE_OTHER',\n    'NOTIFICATION_SENT', 'FBIR_COMPLETED_BY_ANM', 'NEWBORN_SCREENING',\n    'DEATH_REASON_OTHER', 'SNCU_ADMITTED', 'SNCU_REFERRAL_HOSPITAL',\n    'TERTIARY_REFERRAL_HOSPITAL', 'OTHER_REFERRAL_HOSPITAL',\n    'DATE_OF_DEATH', 'REASON_FOR_DEATH', 'PLACE_OF_DEATH',\n    'INDICATION_FOR_C_SECTION', 'CH', 'CAH', 'GALACTOCEMIA', 'G6PDD', 'BIOTINIDASE',\n\n    # Delivery-specific process info\n    'DELIVERY_INSTITUTION', 'DELIVERY_DONE_BY', 'CONDUCT_BY',\n    'MISOPROSTAL_TABLET', 'DEL_COMPLICATIONS', 'OTHER_DEL_COMPLICATIONS',\n    'NOTIFICATION_SENT_del', 'FBIR_COMPLETED_BY_ANM_del',\n\n    # Administrative / logging columns\n    'REGISTRATION_DT', 'REGTYPE', 'CURRENT_USR', 'OTHER_STATE_PLACE',\n    'OTHER_STATE_PLACE_FILEPATH', 'OTHER_GOVT_PLACE_FILEPATH',\n    'ANC2_TAG_FAC_ID', 'ANC3_TAG_FAC_ID',\n\n    # Facility and geographic info\n    'ANC_INSTITUTE', 'FACILITY_TYPE', 'FACILITY_NAME', 'DOCTOR_ANM',\n    'DISTRICT_anc', 'DISTRICT_child',\n\n    # Feeding / newborn care\n    'IS_BF_IN_HOUR', 'FEEDING_TYPE', 'DATE_OF_FIRST_FEEDING',\n    'TIME_OF_FIRST_FEEDING', 'BABY_ON_MEDICATION', 'MEDICATION_REMARKS',\n    'DATE_OF_BLOODSAMPLE_COLLECTION', 'TIME_OF_BLOODSAMPLE_COLLECTION',\n    'HOURS_OF_SAMPLE_COLLECTION', 'TRANSFUSION_DONE',\n\n    # Screening/test results\n    'VDRL_DATE', 'VDRL_STATUS', 'HIV_DATE', 'HIV_STATUS', 'HBSAG_DATE',\n    'HBSAG_STATUS', 'HEP_DATE', 'HEP_STATUS', 'VDRL_RESULT',\n    'HIV_RESULT', 'HBSAG_RESULT', 'HEP_RESULT',\n\n    # Missed ANC flag columns\n    'MISSANC1FLG', 'MISSANC2FLG', 'MISSANC3FLG', 'MISSANC4FLG',\n\n    # Manually added known leaky or post-hoc columns\n    'HIGH_RISKS', 'DISEASES', 'CHILD_NAME',\n\n    # Additional leakage columns\n    'age_category', 'multigravida', 'grand_multipara', 'no_anc',\n    'missed_first_anc', 'consecutive_missed', 'severe_hypertension',\n    'low_birth_weight', 'very_low_birth_weight', 'avg_birth_weight_low',\n    'depression', 'severe_depression', 'anxiety', 'severe_anxiety',\n    'hemoglobin_trend', 'TT_DATE', 'MAL_PRESENT', 'IS_ADMITTED_SNCU',\n    'IS_PREV_PREG', 'ANC1FLG', 'ANC2FLG', 'ANC3FLG', 'ANC4FLG', 'ANC_DATE',\n    'DEATH', 'EXP_DOD', 'DELIVERY_PLACE', 'EXP_DOD_preg', 'FASTING', 'LMP_DT',\n    'SCREENED_FOR_MENTAL_HEALTH', 'AGE', 'AGE_final', 'AGE_preg',\n    'GENDER', 'TIME_OF_BIRTH', 'TWIN_PREGNANCY_max', 'TOTAL_ANC_VISITS', 'RNK',\n    'PHQ_SCORE_max', 'GAD_SCORE_max', 'mental_health_risk', 'NO_OF_WEEKS_max',\n    'DELIVERY_INSTITUTION', 'DELIVERY_DONE_BY', 'CONDUCT_BY', 'OTHER_NAME',\n    'NOTIFICATION_SENT', 'FBIR_COMPLETED_BY_ANM', 'OTHER_STATE_PLACE',\n    'OTHER_STATE_PLACE_FILEPATH', 'OTHER_GOVT_PLACE_FILEPATH',\n    'bp_risk'\n]\n\n# Combine exclude_cols\nexclude_cols = list(set(exclude_cols))\n\n# Select numeric features\nfeatures = [col for col in df.columns if col not in exclude_cols and df[col].dtype in ['float64', 'float32', 'int64', 'int32', 'int8']]\n\nif not features:\n    print(f\"Skipping {target_columns}: No valid features available.\")\nelse:\n    print(f\"Features used for maternal_mortality_risk: {features}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T09:17:05.119150Z","iopub.execute_input":"2025-06-17T09:17:05.119455Z","iopub.status.idle":"2025-06-17T09:17:28.515496Z","shell.execute_reply.started":"2025-06-17T09:17:05.119437Z","shell.execute_reply":"2025-06-17T09:17:28.514690Z"}},"outputs":[{"name":"stdout","text":"Features used for maternal_mortality_risk: ['GRAVIDA', 'PARITY', 'ABORTIONS', 'HEIGHT', 'HEMOGLOBIN_mean', 'HEMOGLOBIN_min', 'HEMOGLOBIN_max', 'WEIGHT_anc_mean', 'WEIGHT_anc_min', 'WEIGHT_anc_max', 'WEIGHT_child_min', 'age_adolescent', 'age_elderly', 'age_very_young', 'previous_loss', 'recurrent_loss', 'gravida_parity_ratio', 'inadequate_anc', 'irregular_anc', 'anemia_mild', 'anemia_moderate', 'anemia_severe', 'ever_severe_anemia', 'systolic_bp', 'diastolic_bp', 'hypertension', 'BMI', 'underweight', 'obese', 'normal_weight', 'weight_gain', 'weight_gain_per_week', 'inadequate_weight_gain']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score, f1_score\nimport lightgbm as lgb\nimport numpy as np\nimport time\n\n# Assuming sample_df, features, and target_column are defined (correcting target_columns to target_column)\nX = sample_df[features]\ny = sample_df[target_columns]  # Changed from target_columns to target_column\n\n# Initial train-test split\nX_train_full, X_test, y_train_full, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# Initialize k-fold cross-validation\nn_splits = 5  # Number of folds\nskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n# Lists to store metrics for each fold\nauc_scores = []\nf1_scores = []\nfold_times = []\n\n# Calculate scale_pos_weight for class imbalance (based on training dataset)\nneg_count = (y_train_full == 0).sum()\npos_count = (y_train_full == 1).sum()\nscale_pos_weight = neg_count[0] / pos_count[0] if pos_count[0] > 0 else 1  # Simplified, assuming y is a Series\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T09:17:36.891695Z","iopub.execute_input":"2025-06-17T09:17:36.891981Z","iopub.status.idle":"2025-06-17T09:17:42.609766Z","shell.execute_reply.started":"2025-06-17T09:17:36.891962Z","shell.execute_reply":"2025-06-17T09:17:42.609166Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"!pip show scikit-learn\n!pip show imbalanced-learn\n!pip install scikit-learn==1.2.2 imbalanced-learn==0.10.1 --no-deps -q\nfrom imblearn.over_sampling import SMOTE\nprint(\"SMOTE imported successfully\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T09:17:50.976913Z","iopub.execute_input":"2025-06-17T09:17:50.977204Z","iopub.status.idle":"2025-06-17T09:17:58.163343Z","shell.execute_reply.started":"2025-06-17T09:17:50.977184Z","shell.execute_reply":"2025-06-17T09:17:58.161947Z"}},"outputs":[{"name":"stdout","text":"Name: scikit-learn\nVersion: 1.2.2\nSummary: A set of python modules for machine learning and data mining\nHome-page: http://scikit-learn.org\nAuthor: \nAuthor-email: \nLicense: new BSD\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: joblib, numpy, scipy, threadpoolctl\nRequired-by: bayesian-optimization, Boruta, category_encoders, cesium, eli5, fastai, hdbscan, hep_ml, imbalanced-learn, librosa, lime, mlxtend, nilearn, pyLDAvis, pynndescent, rgf-python, scikit-learn-intelex, scikit-optimize, scikit-plot, sentence-transformers, shap, sklearn-compat, sklearn-pandas, TPOT, tsfresh, umap-learn, woodwork, yellowbrick\nName: imbalanced-learn\nVersion: 0.13.0\nSummary: Toolbox for imbalanced dataset in machine learning\nHome-page: https://imbalanced-learn.org/\nAuthor: \nAuthor-email: \"G. Lemaitre\" <g.lemaitre58@gmail.com>, \"C. Aridas\" <ichkoar@gmail.com>\nLicense: \nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: joblib, numpy, scikit-learn, scipy, sklearn-compat, threadpoolctl\nRequired-by: \n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hSMOTE imported successfully\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore', category=UserWarning)\nimport pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\nfrom sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix, precision_recall_curve, auc\nfrom imblearn.combine import SMOTEENN\nfrom category_encoders import TargetEncoder\nimport time\nimport shap\nimport matplotlib.pyplot as plt\nimport pyarrow.parquet as pq\n\n# Verify SMOTEENN availability\ntry:\n    from imblearn.combine import SMOTEENN\n    print(\"SMOTEENN imported successfully\")\nexcept ImportError:\n    print(\"Error: SMOTEENN not available. Install: pip install imbalanced-learn==0.10.1\")\n    raise ImportError(\"SMOTEENN is required.\")\n\n# Data loading and preprocessing function\ndef prepare_data_for_targets(data_path, flag_map, batch_size=10000):\n    \"\"\"Load and preprocess data from Parquet file in batches.\"\"\"\n    processed_chunks = []\n    required_cols = ['MOTHER_ID', 'GRAVIDA']\n    numeric_cols = [\n        'GRAVIDA', 'PARITY', 'ABORTIONS', 'HEIGHT', 'HEMOGLOBIN_mean', 'HEMOGLOBIN_min', 'HEMOGLOBIN_max',\n        'WEIGHT_anc_mean', 'WEIGHT_anc_min', 'WEIGHT_anc_max', 'WEIGHT_child_min', 'systolic_bp', 'diastolic_bp',\n        'BMI', 'weight_gain', 'weight_gain_per_week', 'gravida_parity_ratio', 'TOTAL_ANC_VISITS', 'NO_OF_WEEKS_max',\n        'PHQ_SCORE_max', 'GAD_SCORE_max', 'anemia_severe_systolic_bp', 'hypertension_hemoglobin'\n    ]\n    flag_cols = [\n        'age_adolescent', 'age_elderly', 'age_very_young', 'previous_loss', 'recurrent_loss', 'inadequate_anc',\n        'irregular_anc', 'anemia_mild', 'anemia_moderate', 'anemia_severe', 'ever_severe_anemia', 'hypertension',\n        'underweight', 'obese', 'normal_weight', 'inadequate_weight_gain', 'IS_CHILD_DEATH', 'IS_DEFECTIVE_BIRTH'\n    ]\n    categorical_cols = ['FACILITY_TYPE', 'BLOOD_GRP', 'SYS_DISEASE']\n    \n    parquet_file = pq.ParquetFile(data_path)\n    num_rows = parquet_file.metadata.num_rows\n    num_batches = (num_rows + batch_size - 1) // batch_size\n    \n    for batch_idx in range(num_batches):\n        batch = parquet_file.read_row_group(batch_idx).to_pandas() if parquet_file.num_row_groups > batch_idx else pd.DataFrame()\n        if batch.empty:\n            continue\n        \n        for col in required_cols:\n            if col not in batch.columns:\n                raise ValueError(f\"Required column {col} missing in data\")\n        \n        # Convert numeric columns\n        for col in numeric_cols:\n            if col in batch.columns:\n                batch[col] = pd.to_numeric(batch[col], errors='coerce')\n        \n        # Map flag columns\n        for col in flag_cols:\n            if col in batch.columns:\n                if batch[col].dtype == 'object':\n                    batch[col] = batch[col].map(flag_map)\n                batch[col] = batch[col].fillna(0)  # Impute NaNs in flags with 0\n        \n        # Impute numeric NaNs with median\n        for col in numeric_cols:\n            if col in batch.columns and batch[col].isna().any():\n                batch[col] = batch[col].fillna(batch[col].median())\n        \n        # Impute categorical NaNs with mode\n        for col in categorical_cols:\n            if col in batch.columns:\n                mode_val = batch[col].mode().iloc[0] if not batch[col].mode().empty else 'Unknown'\n                batch[col] = batch[col].fillna(mode_val)\n                batch[col] = batch[col].astype(str)  # Ensure string type\n        \n        processed_chunks.append(batch)\n    \n    df = pd.concat(processed_chunks, ignore_index=True)\n    \n    # Limit SYS_DISEASE to top 10 categories\n    if 'SYS_DISEASE' in df.columns:\n        top_categories = df['SYS_DISEASE'].value_counts().index[:10]\n        df['SYS_DISEASE'] = df['SYS_DISEASE'].apply(lambda x: x if x in top_categories else 'Other')\n    \n    # Validate and create interaction features\n    for col in ['anemia_severe', 'systolic_bp', 'hypertension', 'HEMOGLOBIN_mean']:\n        if col in df.columns and df[col].isna().any():\n            print(f\"Warning: Imputing NaNs in {col} before interaction features\")\n            df[col] = df[col].fillna(df[col].median() if col in numeric_cols else 0)\n    \n    if 'anemia_severe' in df.columns and 'systolic_bp' in df.columns:\n        df['anemia_severe_systolic_bp'] = df['anemia_severe'] * df['systolic_bp']\n    if 'hypertension' in df.columns and 'HEMOGLOBIN_mean' in df.columns:\n        df['hypertension_hemoglobin'] = df['hypertension'] * df['HEMOGLOBIN_mean']\n    \n    # Ensure no NaNs in interaction features\n    for col in ['anemia_severe_systolic_bp', 'hypertension_hemoglobin']:\n        if col in df.columns and df[col].isna().any():\n            df[col] = df[col].fillna(df[col].median())\n    \n    return df\n\n# Stratified sampling function\ndef create_stratified_sample(df, target_column, sample_size=1000000, min_positive=1000):\n    \"\"\"Create a stratified sample ensuring all maternal mortality cases are included.\"\"\"\n    if target_column not in df.columns:\n        raise ValueError(f\"Target column '{target_column}' not found in DataFrame. Available columns: {df.columns.tolist()}\")\n    \n    maternal_deaths = df[df[target_column] == 1]\n    print(f\"Found {len(maternal_deaths)} maternal mortality cases\")\n    \n    critical_cases = maternal_deaths.drop_duplicates()\n    \n    if len(critical_cases) == 0:\n        raise ValueError(f\"No positive cases ({target_column}=1) found.\")\n    if len(critical_cases) < min_positive:\n        print(f\"Warning: Only {len(critical_cases)} positive cases found. Oversampling to {min_positive}.\")\n        oversampled_positives = critical_cases.sample(n=min_positive, replace=True, random_state=42)\n        critical_cases = pd.concat([critical_cases, oversampled_positives]).drop_duplicates()\n    \n    remaining_size = sample_size - len(critical_cases)\n    if remaining_size > 0:\n        other_cases = df[~df.index.isin(critical_cases.index)]\n        if len(other_cases) < remaining_size:\n            print(f\"Warning: Only {len(other_cases)} non-critical cases available. Adjusting sample size.\")\n            remaining_size = len(other_cases)\n        sampled_others = other_cases.sample(n=remaining_size, random_state=42)\n        final_sample = pd.concat([critical_cases, sampled_others])\n    else:\n        final_sample = critical_cases.sample(n=sample_size, random_state=42)\n    \n    return final_sample\n\n# Main script\ndata_path = '/kaggle/input/fullfinal/telangana_data_with_features_and_targets (1).parquet'\nflag_map = {\n    'Y': 1, 'YES': 1, 'Yes': 1, 'y': 1, 'yes': 1,\n    'N': 0, 'NO': 0, 'No': 0, 'n': 0, 'no': 0,\n    None: np.nan, 'None': np.nan, '': np.nan, 'nan': np.nan, 'NULL': np.nan, 'missing': np.nan\n}\n\n# Load and preprocess data\ndf = prepare_data_for_targets(data_path, flag_map)\n\n# Diagnostic checks\nprint(\"Columns in df:\", df.columns.tolist())\nprint(\"maternal_mortality_risk distribution:\")\nprint(df['maternal_mortality_risk'].value_counts(dropna=False))\n\n# Select target\ntarget_column = 'maternal_mortality_risk'\nif df[target_column].eq(1).sum() == 0:\n    raise ValueError(f\"No positive cases found for {target_column}. Cannot proceed.\")\nprint(f\"Using target: {target_column}\")\n\n# Create sample\nsample_df = create_stratified_sample(df, target_column)\nprint(f\"Class distribution in sample_df for {target_column}:\")\nprint(sample_df[target_column].value_counts())\n\n# Select features\nnumeric_features = [\n    'GRAVIDA', 'PARITY', 'ABORTIONS', 'HEIGHT', 'HEMOGLOBIN_mean', 'HEMOGLOBIN_min', 'HEMOGLOBIN_max',\n    'WEIGHT_anc_mean', 'WEIGHT_anc_min', 'WEIGHT_anc_max', 'WEIGHT_child_min', 'systolic_bp', 'diastolic_bp',\n    'BMI', 'weight_gain', 'weight_gain_per_week', 'gravida_parity_ratio', 'TOTAL_ANC_VISITS', 'NO_OF_WEEKS_max',\n    'anemia_severe_systolic_bp', 'hypertension_hemoglobin'\n]\nflag_features = [\n    'age_adolescent', 'age_elderly', 'age_very_young', 'previous_loss', 'recurrent_loss', 'inadequate_anc',\n    'irregular_anc', 'anemia_mild', 'anemia_moderate', 'anemia_severe', 'ever_severe_anemia', 'hypertension',\n    'underweight', 'obese', 'normal_weight', 'inadequate_weight_gain'\n]\ncategorical_features = ['FACILITY_TYPE', 'BLOOD_GRP', 'SYS_DISEASE']\nfeatures = numeric_features + flag_features + categorical_features\n\nif not features:\n    raise ValueError(f\"No valid features available for {target_column}. Available columns: {df.columns.tolist()}\")\nprint(\"Features used:\", features)\n\n# Prepare data\nX = sample_df[features]\ny = sample_df[target_column]\n\n# Check for NaNs before encoding\nprint(\"Checking for NaNs in X before encoding:\")\nprint(X.isna().sum())\nfor col in X.columns:\n    if X[col].isna().any():\n        if col in numeric_features:\n            X[col] = X[col].fillna(X[col].median())\n        elif col in categorical_features:\n            mode_val = X[col].mode().iloc[0] if not X[col].mode().empty else 'Unknown'\n            X[col] = X[col].fillna(mode_val)\n        elif col in flag_features:\n            X[col] = X[col].fillna(0)\n\n# Encode categorical features\nencoder = TargetEncoder(cols=categorical_features, handle_missing='value', handle_unknown='value')\nX = encoder.fit_transform(X, y)\n\n# Check for NaNs after encoding\nprint(\"Checking for NaNs in X after encoding:\")\nprint(X.isna().sum())\nX = X.fillna(X.median(numeric_only=True))  # Impute any remaining NaNs\n\n# Initial train-test split\nX_train_full, X_test, y_train_full, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# Initialize k-fold cross-validation\nn_splits = 5\nskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n\n# Metrics storage\nmetrics = {\n    'thresh_0_1': {'f1': [], 'accuracy': [], 'precision': [], 'recall': [], 'pr_auc': []},\n    'thresh_0_2': {'f1': [], 'accuracy': [], 'precision': [], 'recall': [], 'pr_auc': []},\n    'thresh_0_3': {'f1': [], 'accuracy': [], 'precision': [], 'recall': [], 'pr_auc': []},\n    'thresh_0_4': {'f1': [], 'accuracy': [], 'precision': [], 'recall': [], 'pr_auc': []},\n    'auc': []\n}\nfold_models = []\nfold_times = []\nfold_avg_f1 = []\n\n# Calculate scale_pos_weight\nneg_count = (y_train_full == 0).sum()\npos_count = (y_train_full == 1).sum()\nscale_pos_weight = neg_count / pos_count * 1.5\nprint(f\"Scale pos weight: {scale_pos_weight:.2f}\")\n\n# LightGBM parameters\nparams = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'n_estimators': 500,\n    'max_depth': 7,\n    'learning_rate': 0.05,\n    'scale_pos_weight': scale_pos_weight,\n    'min_child_weight': 5,\n    'random_state': 42,\n    'n_jobs': -1,\n    'verbosity': -1\n}\n\n# K-fold cross-validation\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X_train_full, y_train_full)):\n    print(f\"Training fold {fold + 1}/{n_splits}\")\n    \n    X_train, X_val = X_train_full.iloc[train_idx], X_train_full.iloc[val_idx]\n    y_train, y_val = y_train_full.iloc[train_idx], y_train_full.iloc[val_idx]\n    \n    print(f\"Training class counts:\\n{y_train.value_counts()}\")\n    print(f\"Validation class counts:\\n{y_val.value_counts()}\")\n    \n    if len(y_train.unique()) < 2 or len(y_val.unique()) < 2:\n        print(f\"Warning: Fold {fold + 1} has only one class. Skipping.\")\n        continue\n    \n    # Check for NaNs before SMOTEENN\n    print(f\"Checking for NaNs in X_train before SMOTEENN for fold {fold + 1}:\")\n    print(X_train.isna().sum())\n    if X_train.isna().any().any():\n        for col in X_train.columns:\n            if X_train[col].isna().any():\n                if col in numeric_features:\n                    X_train[col] = X_train[col].fillna(X_train[col].median())\n                    X_val[col] = X_val[col].fillna(X_train[col].median())\n                elif col in categorical_features:\n                    mode_val = X_train[col].mode().iloc[0] if not X_train[col].mode().empty else 'Unknown'\n                    X_train[col] = X_train[col].fillna(mode_val)\n                    X_val[col] = X_val[col].fillna(mode_val)\n                elif col in flag_features:\n                    X_train[col] = X_train[col].fillna(0)\n                    X_val[col] = X_val[col].fillna(0)\n    \n    # Verify no NaNs remain\n    if X_train.isna().any().any():\n        raise ValueError(f\"NaNs remain in X_train after imputation in fold {fold + 1}\")\n    \n    # Apply SMOTEENN\n    print(f\"Applying SMOTEENN for fold {fold + 1}\")\n    smoteenn = SMOTEENN(random_state=42, sampling_strategy=0.1)\n    X_train, y_train = smoteenn.fit_resample(X_train, y_train)\n    print(f\"Post-SMOTEENN training class counts:\\n{y_train.value_counts()}\")\n    \n    start_time = time.time()\n    model = lgb.LGBMClassifier(**params)\n    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], eval_metric='auc', callbacks=[lgb.early_stopping(50, verbose=False)])\n    fold_time = time.time() - start_time\n    fold_models.append(model)\n    fold_times.append(fold_time)\n    \n    y_pred_proba = model.predict_proba(X_val)[:, 1]\n    precisions, recalls, pr_thresholds = precision_recall_curve(y_val, y_pred_proba)\n    pr_auc = auc(recalls, precisions)\n    \n    for thresh, thresh_name in [(0.1, 'thresh_0_1'), (0.2, 'thresh_0_2'), (0.3, 'thresh_0_3'), (0.4, 'thresh_0_4')]:\n        y_pred = (y_pred_proba > thresh).astype(int)\n        metrics[thresh_name]['f1'].append(f1_score(y_val, y_pred))\n        metrics[thresh_name]['accuracy'].append(accuracy_score(y_val, y_pred))\n        metrics[thresh_name]['precision'].append(precision_score(y_val, y_pred, zero_division=0))\n        metrics[thresh_name]['recall'].append(recall_score(y_val, y_pred, zero_division=0))\n        metrics[thresh_name]['pr_auc'].append(pr_auc)\n    \n    auc_score = roc_auc_score(y_val, y_pred_proba) if len(np.unique(y_val)) > 1 else 0\n    metrics['auc'].append(auc_score)\n    \n    avg_f1 = np.mean([metrics[f'thresh_0_{i}']['f1'][-1] for i in [1, 2, 3, 4]])\n    fold_avg_f1.append(avg_f1)\n    \n    print(f\"Fold {fold + 1}\")\n    print(f\"  AUC: {auc_score:.4f}, PR-AUC: {pr_auc:.4f}, Time: {fold_time:.2f} seconds\")\n    for thresh, thresh_name in [(0.1, 'thresh_0_1'), (0.2, 'thresh_0_2'), (0.3, 'thresh_0_3'), (0.4, 'thresh_0_4')]:\n        print(f\"  Threshold {thresh} - F1: {metrics[thresh_name]['f1'][-1]:.4f}, Accuracy: {metrics[thresh_name]['accuracy'][-1]:.4f}, \"\n              f\"Precision: {metrics[thresh_name]['precision'][-1]:.4f}, Recall: {metrics[thresh_name]['recall'][-1]:.4f}\")\n        print(f\"  Confusion Matrix (Threshold {thresh}):\\n{confusion_matrix(y_val, (y_pred_proba > thresh).astype(int))}\")\n\n# Cross-validation results\nprint(f\"\\nCross-Validation Mean Metrics:\")\nprint(f\"  AUC: {np.mean(metrics['auc']):.4f} ± {np.std(metrics['auc']):.4f}\")\nfor thresh_name in ['thresh_0_1', 'thresh_0_2', 'thresh_0_3', 'thresh_0_4']:\n    print(f\"\\n{thresh_name.replace('_', ' ').title()}:\")\n    print(f\"  F1 Score: {np.mean(metrics[thresh_name]['f1']):.4f} ± {np.std(metrics[thresh_name]['f1']):.4f}\")\n    print(f\"  Accuracy: {np.mean(metrics[thresh_name]['accuracy']):.4f} ± {np.std(metrics[thresh_name]['accuracy']):.4f}\")\n    print(f\"  Precision: {np.mean(metrics[thresh_name]['precision']):.4f} ± {np.std(metrics[thresh_name]['precision']):.4f}\")\n    print(f\"  Recall: {np.mean(metrics[thresh_name]['recall']):.4f} ± {np.std(metrics[thresh_name]['recall']):.4f}\")\n    print(f\"  PR-AUC: {np.mean(metrics[thresh_name]['pr_auc']):.4f} ± {np.std(metrics[thresh_name]['pr_auc']):.4f}\")\n\n# Evaluate best model on test set\nif fold_avg_f1:\n    best_fold_idx = np.argmax(fold_avg_f1)\n    best_model = fold_models[best_fold_idx]\n    print(f\"\\nBest Model from Fold {best_fold_idx + 1} with Average F1 Score: {fold_avg_f1[best_fold_idx]:.4f}\")\n    \n    y_test_pred_proba = best_model.predict_proba(X_test)[:, 1]\n    precisions, recalls, _ = precision_recall_curve(y_test, y_test_pred_proba)\n    test_pr_auc = auc(recalls, precisions)\n    \n    test_metrics = {}\n    for thresh in [0.1, 0.2, 0.3, 0.4]:\n        y_test_pred = (y_test_pred_proba > thresh).astype(int)\n        test_metrics[thresh] = {\n            'f1': f1_score(y_test, y_test_pred),\n            'accuracy': accuracy_score(y_test, y_test_pred),\n            'precision': precision_score(y_test, y_test_pred, zero_division=0),\n            'recall': recall_score(y_test, y_test_pred, zero_division=0),\n            'cm': confusion_matrix(y_test, y_test_pred)\n        }\n    \n    test_auc = roc_auc_score(y_test, y_test_pred_proba) if len(np.unique(y_test)) > 1 else 0\n    print(f\"\\nTest Set Metrics (Best Model from Fold {best_fold_idx + 1}):\")\n    print(f\"  AUC: {test_auc:.4f}, PR-AUC: {test_pr_auc:.4f}\")\n    for thresh in [0.1, 0.2, 0.3, 0.4]:\n        print(f\"\\nThreshold {thresh}:\\n  F1: {test_metrics[thresh]['f1']:.4f}, Accuracy: {test_metrics[thresh]['accuracy']:.4f}, \"\n              f\"Precision: {test_metrics[thresh]['precision']:.4f}, Recall: {test_metrics[thresh]['recall']:.4f}\\n  \"\n              f\"Confusion Matrix:\\n{test_metrics[thresh]['cm']}\")\n    \n    test_f1_scores = {thresh: test_metrics[thresh]['f1'] for thresh in [0.1, 0.2, 0.3, 0.4]}\n    best_threshold = max(test_f1_scores, key=test_f1_scores.get)\n    print(f\"\\nBest Threshold on Test Set: {best_threshold} with F1 Score: {test_f1_scores[best_threshold]:.4f}\")\n    \n    # SHAP analysis\n    print(\"\\nPerforming SHAP analysis...\")\n    X_test_sample = X_test.sample(n=min(1000, len(X_test)), random_state=42)\n    explainer = shap.TreeExplainer(best_model)\n    shap_values = explainer.shap_values(X_test_sample)[1]  # Use positive class SHAP values\n    \n    plt.figure()\n    shap.summary_plot(shap_values, X_test_sample, show=False)\n    plt.savefig(\"shap_summary_plot_maternal.png\")\n    plt.close()\n    print(\"SHAP summary plot saved as 'shap_summary_plot_maternal.png'\")\n    \n    plt.figure()\n    shap.summary_plot(shap_values, X_test_sample, plot_type=\"bar\", show=False)\n    plt.savefig(\"shap_importance_bar_maternal.png\")\n    plt.close()\n    print(\"SHAP feature importance bar plot saved as 'shap_importance_bar_maternal.png'\")\n    \n    shap_importance = np.abs(shap_values).mean(axis=0)\n    importance_df = pd.DataFrame({\n        'Feature': X_test_sample.columns,\n        'SHAP_Importance': shap_importance\n    }).sort_values(by='SHAP_Importance', ascending=False)\n    print(\"\\nSHAP Feature Importance:\")\n    print(importance_df)\nelse:\n    print(\"\\nNo valid models trained due to single-class folds.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-17T09:18:08.097549Z","iopub.execute_input":"2025-06-17T09:18:08.097849Z","iopub.status.idle":"2025-06-17T10:52:24.570662Z","shell.execute_reply.started":"2025-06-17T09:18:08.097826Z","shell.execute_reply":"2025-06-17T10:52:24.568633Z"}},"outputs":[{"name":"stdout","text":"SMOTEENN imported successfully\nColumns in df: ['ANC_ID', 'MOTHER_ID', 'GRAVIDA', 'ANC_DATE', 'ANC_INSTITUTE', 'FACILITY_TYPE', 'FACILITY_NAME', 'DOCTOR_ANM', 'BLOOD_SUGAR', 'IFA_TABLET', 'TT_GIVEN', 'USG_SCAN', 'MAL_PRESENT', 'PLACENTA', 'HIV', 'THYROID', 'RH_NEGATIVE', 'SYS_DISEASE', 'DISTRICT_anc', 'EXP_DOD', 'ANC_TYPE', 'URINE_TEST', 'URINE_SUGAR', 'URINE_ALBUMIN', 'UTERUS_SIZE', 'HEART_RATE', 'FOETAL_POSITION', 'FASTING', 'TT_DATE', 'POST_PRANDIAL', 'BLOOD_SUGAR_TEST', 'IRON_SUCROSE_INJ', 'SCREENED_FOR_MENTAL_HEALTH', 'PARA_TO_WARNING_SIGNS_HTN', 'RNK', 'unique_id', 'CHILD_ID', 'GENDER', 'TIME_OF_BIRTH', 'IS_DEFECTIVE_BIRTH', 'IS_BF_IN_HOUR', 'AGE', 'DELIVERY_PLACE', 'DELIVERY_MODE', 'IS_PREV_PREG', 'IS_ADMITTED_SNCU', 'SNCU_REFERRAL_HOSPITAL', 'TERTIARY_REFERRAL_HOSPITAL', 'OTHER_REFERRAL_HOSPITAL', 'CHILD_DEATH_DATE', 'CHILD_DEATH_REASON', 'IMMUNE_CYCLE_DONE', 'DISTRICT_child', 'DEFECT_HEALTH_CENTER', 'IS_CHILD_DEATH', 'BIRTH_DEFECT_TYPE', 'BIRTH_DEFECT_SUBTYPE', 'DEFECT_SUBTYPE_OTHER', 'NOTIFICATION_SENT', 'FBIR_COMPLETED_BY_ANM', 'CHILD_NAME', 'BIRTH_SCREENING', 'DEFECT_TYPE_OTHER', 'DEATH_REASON_OTHER', 'NEWBORN_SCREENING', 'EID', 'UID_NUMBER', 'SNCU_ADMITTED', 'CONSANGUINITY', 'HIGH_RISKS', 'DISEASES', 'FEEDING_TYPE', 'DATE_OF_FIRST_FEEDING', 'TIME_OF_FIRST_FEEDING', 'DATE_OF_BLOODSAMPLE_COLLECTION', 'TIME_OF_BLOODSAMPLE_COLLECTION', 'HOURS_OF_SAMPLE_COLLECTION', 'TRANSFUSION_DONE', 'BABY_ON_MEDICATION', 'CH', 'CAH', 'GALACTOCEMIA', 'G6PDD', 'BIOTINIDASE', 'MEDICATION_REMARKS', 'DATE_OF_DELIVERY', 'PLACE_OF_DELIVERY', 'DELIVERY_OUTCOME', 'MODE_OF_DELIVERY', 'MATERNAL_OUTCOME', 'REASON_FOR_DEATH', 'DATE_OF_DEATH', 'PLACE_OF_DEATH', 'INDICATION_FOR_C_SECTION', 'DELIVERY_INSTITUTION', 'DELIVERY_DONE_BY', 'IS_DELIVERED', 'DATE_OF_DISCHARGE', 'IS_MOTHER_ALIVE', 'DEL_TIME', 'MISOPROSTAL_TABLET', 'CONDUCT_BY', 'OTHER_NAME', 'JSY_BENEFICIARY', 'DISCHARGE_TIME', 'DEL_COMPLICATIONS', 'OTHER_DEL_COMPLICATIONS', 'NOTIFICATION_SENT_del', 'FBIR_COMPLETED_BY_ANM_del', 'OTHER_STATE_PLACE', 'OTHER_STATE_PLACE_FILEPATH', 'OTHER_GOVT_PLACE_FILEPATH', 'REGISTRATION_DT', 'LMP_DT', 'EXP_DOD_preg', 'PARITY', 'ABORTIONS', 'LIVE', 'DEATH', 'OBSTETRIC_FORMULA', 'AGE_preg', 'HEIGHT', 'BLOOD_GRP', 'ANC1FLG', 'ANC2FLG', 'ANC3FLG', 'ANC4FLG', 'MISSANC1FLG', 'MISSANC2FLG', 'MISSANC3FLG', 'MISSANC4FLG', 'REGTYPE', 'CURRENT_USR', 'ANC2_TAG_FAC_DIST', 'ANC2_TAG_FAC_ID', 'ANC3_TAG_FAC_DIST', 'ANC3_TAG_FAC_ID', 'VDRL_DATE', 'VDRL_STATUS', 'VDRL_RESULT', 'HIV_DATE', 'HIV_STATUS', 'HIV_RESULT', 'HBSAG_DATE', 'HBSAG_STATUS', 'HBSAG_RESULT', 'HEP_DATE', 'HEP_STATUS', 'HEP_RESULT', 'HEMOGLOBIN_mean', 'HEMOGLOBIN_min', 'HEMOGLOBIN_max', 'WEIGHT_anc_mean', 'WEIGHT_anc_min', 'WEIGHT_anc_max', 'BP_last', 'NO_OF_WEEKS_max', 'TWIN_PREGNANCY_max', 'PHQ_SCORE_max', 'GAD_SCORE_max', 'TOTAL_ANC_VISITS', 'WEIGHT_child_mean', 'WEIGHT_child_min', 'AGE_final', 'age_adolescent', 'age_elderly', 'age_very_young', 'age_risk_score', 'age_category', 'multigravida', 'grand_multipara', 'previous_loss', 'recurrent_loss', 'gravida_parity_ratio', 'inadequate_anc', 'no_anc', 'total_missed_visits', 'irregular_anc', 'missed_first_anc', 'consecutive_missed', 'anemia_mild', 'anemia_moderate', 'anemia_severe', 'ever_severe_anemia', 'anemia_risk_score', 'hemoglobin_trend', 'systolic_bp', 'diastolic_bp', 'hypertension', 'severe_hypertension', 'bp_risk', 'BMI', 'underweight', 'obese', 'normal_weight', 'depression', 'severe_depression', 'anxiety', 'severe_anxiety', 'mental_health_risk', 'weight_gain', 'weight_gain_per_week', 'inadequate_weight_gain', 'low_birth_weight', 'very_low_birth_weight', 'avg_birth_weight_low', 'demographic_risk', 'clinical_risk_score', 'overall_risk_score', 'maternal_mortality_risk', 'stillbirth_risk', 'premature_birth_risk', 'anc_dropout', 'total_risk_factors', 'high_risk_pregnancy', 'anemia_severe_systolic_bp', 'hypertension_hemoglobin']\nmaternal_mortality_risk distribution:\nmaternal_mortality_risk\n0    4028194\n1       1377\nName: count, dtype: int64\nUsing target: maternal_mortality_risk\nFound 1377 maternal mortality cases\nClass distribution in sample_df for maternal_mortality_risk:\nmaternal_mortality_risk\n0    998623\n1      1377\nName: count, dtype: int64\nFeatures used: ['GRAVIDA', 'PARITY', 'ABORTIONS', 'HEIGHT', 'HEMOGLOBIN_mean', 'HEMOGLOBIN_min', 'HEMOGLOBIN_max', 'WEIGHT_anc_mean', 'WEIGHT_anc_min', 'WEIGHT_anc_max', 'WEIGHT_child_min', 'systolic_bp', 'diastolic_bp', 'BMI', 'weight_gain', 'weight_gain_per_week', 'gravida_parity_ratio', 'TOTAL_ANC_VISITS', 'NO_OF_WEEKS_max', 'anemia_severe_systolic_bp', 'hypertension_hemoglobin', 'age_adolescent', 'age_elderly', 'age_very_young', 'previous_loss', 'recurrent_loss', 'inadequate_anc', 'irregular_anc', 'anemia_mild', 'anemia_moderate', 'anemia_severe', 'ever_severe_anemia', 'hypertension', 'underweight', 'obese', 'normal_weight', 'inadequate_weight_gain', 'FACILITY_TYPE', 'BLOOD_GRP', 'SYS_DISEASE']\nChecking for NaNs in X before encoding:\nGRAVIDA                      0\nPARITY                       0\nABORTIONS                    0\nHEIGHT                       0\nHEMOGLOBIN_mean              0\nHEMOGLOBIN_min               0\nHEMOGLOBIN_max               0\nWEIGHT_anc_mean              0\nWEIGHT_anc_min               0\nWEIGHT_anc_max               0\nWEIGHT_child_min             0\nsystolic_bp                  0\ndiastolic_bp                 0\nBMI                          0\nweight_gain                  0\nweight_gain_per_week         0\ngravida_parity_ratio         0\nTOTAL_ANC_VISITS             0\nNO_OF_WEEKS_max              0\nanemia_severe_systolic_bp    0\nhypertension_hemoglobin      0\nage_adolescent               0\nage_elderly                  0\nage_very_young               0\nprevious_loss                0\nrecurrent_loss               0\ninadequate_anc               0\nirregular_anc                0\nanemia_mild                  0\nanemia_moderate              0\nanemia_severe                0\never_severe_anemia           0\nhypertension                 0\nunderweight                  0\nobese                        0\nnormal_weight                0\ninadequate_weight_gain       0\nFACILITY_TYPE                0\nBLOOD_GRP                    0\nSYS_DISEASE                  0\ndtype: int64\nChecking for NaNs in X after encoding:\nGRAVIDA                      0\nPARITY                       0\nABORTIONS                    0\nHEIGHT                       0\nHEMOGLOBIN_mean              0\nHEMOGLOBIN_min               0\nHEMOGLOBIN_max               0\nWEIGHT_anc_mean              0\nWEIGHT_anc_min               0\nWEIGHT_anc_max               0\nWEIGHT_child_min             0\nsystolic_bp                  0\ndiastolic_bp                 0\nBMI                          0\nweight_gain                  0\nweight_gain_per_week         0\ngravida_parity_ratio         0\nTOTAL_ANC_VISITS             0\nNO_OF_WEEKS_max              0\nanemia_severe_systolic_bp    0\nhypertension_hemoglobin      0\nage_adolescent               0\nage_elderly                  0\nage_very_young               0\nprevious_loss                0\nrecurrent_loss               0\ninadequate_anc               0\nirregular_anc                0\nanemia_mild                  0\nanemia_moderate              0\nanemia_severe                0\never_severe_anemia           0\nhypertension                 0\nunderweight                  0\nobese                        0\nnormal_weight                0\ninadequate_weight_gain       0\nFACILITY_TYPE                0\nBLOOD_GRP                    0\nSYS_DISEASE                  0\ndtype: int64\nScale pos weight: 1087.43\nTraining fold 1/5\nTraining class counts:\nmaternal_mortality_risk\n0    639118\n1       882\nName: count, dtype: int64\nValidation class counts:\nmaternal_mortality_risk\n0    159780\n1       220\nName: count, dtype: int64\nChecking for NaNs in X_train before SMOTEENN for fold 1:\nGRAVIDA                      0\nPARITY                       0\nABORTIONS                    0\nHEIGHT                       0\nHEMOGLOBIN_mean              0\nHEMOGLOBIN_min               0\nHEMOGLOBIN_max               0\nWEIGHT_anc_mean              0\nWEIGHT_anc_min               0\nWEIGHT_anc_max               0\nWEIGHT_child_min             0\nsystolic_bp                  0\ndiastolic_bp                 0\nBMI                          0\nweight_gain                  0\nweight_gain_per_week         0\ngravida_parity_ratio         0\nTOTAL_ANC_VISITS             0\nNO_OF_WEEKS_max              0\nanemia_severe_systolic_bp    0\nhypertension_hemoglobin      0\nage_adolescent               0\nage_elderly                  0\nage_very_young               0\nprevious_loss                0\nrecurrent_loss               0\ninadequate_anc               0\nirregular_anc                0\nanemia_mild                  0\nanemia_moderate              0\nanemia_severe                0\never_severe_anemia           0\nhypertension                 0\nunderweight                  0\nobese                        0\nnormal_weight                0\ninadequate_weight_gain       0\nFACILITY_TYPE                0\nBLOOD_GRP                    0\nSYS_DISEASE                  0\ndtype: int64\nApplying SMOTEENN for fold 1\nPost-SMOTEENN training class counts:\nmaternal_mortality_risk\n0    631110\n1     61145\nName: count, dtype: int64\nFold 1\n  AUC: 0.6551, PR-AUC: 0.0032, Time: 7.17 seconds\n  Threshold 0.1 - F1: 0.0028, Accuracy: 0.0380, Precision: 0.0014, Recall: 0.9864\n  Confusion Matrix (Threshold 0.1):\n[[  5860 153920]\n [     3    217]]\n  Threshold 0.2 - F1: 0.0029, Accuracy: 0.0943, Precision: 0.0015, Recall: 0.9636\n  Confusion Matrix (Threshold 0.2):\n[[ 14883 144897]\n [     8    212]]\n  Threshold 0.3 - F1: 0.0031, Accuracy: 0.1571, Precision: 0.0015, Recall: 0.9455\n  Confusion Matrix (Threshold 0.3):\n[[ 24930 134850]\n [    12    208]]\n  Threshold 0.4 - F1: 0.0032, Accuracy: 0.2196, Precision: 0.0016, Recall: 0.9182\n  Confusion Matrix (Threshold 0.4):\n[[ 34935 124845]\n [    18    202]]\nTraining fold 2/5\nTraining class counts:\nmaternal_mortality_risk\n0    639118\n1       882\nName: count, dtype: int64\nValidation class counts:\nmaternal_mortality_risk\n0    159780\n1       220\nName: count, dtype: int64\nChecking for NaNs in X_train before SMOTEENN for fold 2:\nGRAVIDA                      0\nPARITY                       0\nABORTIONS                    0\nHEIGHT                       0\nHEMOGLOBIN_mean              0\nHEMOGLOBIN_min               0\nHEMOGLOBIN_max               0\nWEIGHT_anc_mean              0\nWEIGHT_anc_min               0\nWEIGHT_anc_max               0\nWEIGHT_child_min             0\nsystolic_bp                  0\ndiastolic_bp                 0\nBMI                          0\nweight_gain                  0\nweight_gain_per_week         0\ngravida_parity_ratio         0\nTOTAL_ANC_VISITS             0\nNO_OF_WEEKS_max              0\nanemia_severe_systolic_bp    0\nhypertension_hemoglobin      0\nage_adolescent               0\nage_elderly                  0\nage_very_young               0\nprevious_loss                0\nrecurrent_loss               0\ninadequate_anc               0\nirregular_anc                0\nanemia_mild                  0\nanemia_moderate              0\nanemia_severe                0\never_severe_anemia           0\nhypertension                 0\nunderweight                  0\nobese                        0\nnormal_weight                0\ninadequate_weight_gain       0\nFACILITY_TYPE                0\nBLOOD_GRP                    0\nSYS_DISEASE                  0\ndtype: int64\nApplying SMOTEENN for fold 2\nPost-SMOTEENN training class counts:\nmaternal_mortality_risk\n0    631339\n1     61046\nName: count, dtype: int64\nFold 2\n  AUC: 0.6410, PR-AUC: 0.0031, Time: 8.33 seconds\n  Threshold 0.1 - F1: 0.0029, Accuracy: 0.0890, Precision: 0.0014, Recall: 0.9591\n  Confusion Matrix (Threshold 0.1):\n[[ 14024 145756]\n [     9    211]]\n  Threshold 0.2 - F1: 0.0030, Accuracy: 0.1721, Precision: 0.0015, Recall: 0.9091\n  Confusion Matrix (Threshold 0.2):\n[[ 27330 132450]\n [    20    200]]\n  Threshold 0.3 - F1: 0.0032, Accuracy: 0.2504, Precision: 0.0016, Recall: 0.8682\n  Confusion Matrix (Threshold 0.3):\n[[ 39868 119912]\n [    29    191]]\n  Threshold 0.4 - F1: 0.0033, Accuracy: 0.3286, Precision: 0.0017, Recall: 0.8182\n  Confusion Matrix (Threshold 0.4):\n[[ 52403 107377]\n [    40    180]]\nTraining fold 3/5\nTraining class counts:\nmaternal_mortality_risk\n0    639118\n1       882\nName: count, dtype: int64\nValidation class counts:\nmaternal_mortality_risk\n0    159780\n1       220\nName: count, dtype: int64\nChecking for NaNs in X_train before SMOTEENN for fold 3:\nGRAVIDA                      0\nPARITY                       0\nABORTIONS                    0\nHEIGHT                       0\nHEMOGLOBIN_mean              0\nHEMOGLOBIN_min               0\nHEMOGLOBIN_max               0\nWEIGHT_anc_mean              0\nWEIGHT_anc_min               0\nWEIGHT_anc_max               0\nWEIGHT_child_min             0\nsystolic_bp                  0\ndiastolic_bp                 0\nBMI                          0\nweight_gain                  0\nweight_gain_per_week         0\ngravida_parity_ratio         0\nTOTAL_ANC_VISITS             0\nNO_OF_WEEKS_max              0\nanemia_severe_systolic_bp    0\nhypertension_hemoglobin      0\nage_adolescent               0\nage_elderly                  0\nage_very_young               0\nprevious_loss                0\nrecurrent_loss               0\ninadequate_anc               0\nirregular_anc                0\nanemia_mild                  0\nanemia_moderate              0\nanemia_severe                0\never_severe_anemia           0\nhypertension                 0\nunderweight                  0\nobese                        0\nnormal_weight                0\ninadequate_weight_gain       0\nFACILITY_TYPE                0\nBLOOD_GRP                    0\nSYS_DISEASE                  0\ndtype: int64\nApplying SMOTEENN for fold 3\nPost-SMOTEENN training class counts:\nmaternal_mortality_risk\n0    631161\n1     60989\nName: count, dtype: int64\nFold 3\n  AUC: 0.5967, PR-AUC: 0.0021, Time: 2.90 seconds\n  Threshold 0.1 - F1: 0.0028, Accuracy: 0.0236, Precision: 0.0014, Recall: 0.9955\n  Confusion Matrix (Threshold 0.1):\n[[  3561 156219]\n [     1    219]]\n  Threshold 0.2 - F1: 0.0000, Accuracy: 0.9986, Precision: 0.0000, Recall: 0.0000\n  Confusion Matrix (Threshold 0.2):\n[[159776      4]\n [   220      0]]\n  Threshold 0.3 - F1: 0.0000, Accuracy: 0.9986, Precision: 0.0000, Recall: 0.0000\n  Confusion Matrix (Threshold 0.3):\n[[159780      0]\n [   220      0]]\n  Threshold 0.4 - F1: 0.0000, Accuracy: 0.9986, Precision: 0.0000, Recall: 0.0000\n  Confusion Matrix (Threshold 0.4):\n[[159780      0]\n [   220      0]]\nTraining fold 4/5\nTraining class counts:\nmaternal_mortality_risk\n0    639119\n1       881\nName: count, dtype: int64\nValidation class counts:\nmaternal_mortality_risk\n0    159779\n1       221\nName: count, dtype: int64\nChecking for NaNs in X_train before SMOTEENN for fold 4:\nGRAVIDA                      0\nPARITY                       0\nABORTIONS                    0\nHEIGHT                       0\nHEMOGLOBIN_mean              0\nHEMOGLOBIN_min               0\nHEMOGLOBIN_max               0\nWEIGHT_anc_mean              0\nWEIGHT_anc_min               0\nWEIGHT_anc_max               0\nWEIGHT_child_min             0\nsystolic_bp                  0\ndiastolic_bp                 0\nBMI                          0\nweight_gain                  0\nweight_gain_per_week         0\ngravida_parity_ratio         0\nTOTAL_ANC_VISITS             0\nNO_OF_WEEKS_max              0\nanemia_severe_systolic_bp    0\nhypertension_hemoglobin      0\nage_adolescent               0\nage_elderly                  0\nage_very_young               0\nprevious_loss                0\nrecurrent_loss               0\ninadequate_anc               0\nirregular_anc                0\nanemia_mild                  0\nanemia_moderate              0\nanemia_severe                0\never_severe_anemia           0\nhypertension                 0\nunderweight                  0\nobese                        0\nnormal_weight                0\ninadequate_weight_gain       0\nFACILITY_TYPE                0\nBLOOD_GRP                    0\nSYS_DISEASE                  0\ndtype: int64\nApplying SMOTEENN for fold 4\nPost-SMOTEENN training class counts:\nmaternal_mortality_risk\n0    631081\n1     60957\nName: count, dtype: int64\nFold 4\n  AUC: 0.6352, PR-AUC: 0.0033, Time: 7.50 seconds\n  Threshold 0.1 - F1: 0.0029, Accuracy: 0.0534, Precision: 0.0015, Recall: 0.9955\n  Confusion Matrix (Threshold 0.1):\n[[  8324 151455]\n [     1    220]]\n  Threshold 0.2 - F1: 0.0030, Accuracy: 0.1284, Precision: 0.0015, Recall: 0.9593\n  Confusion Matrix (Threshold 0.2):\n[[ 20339 139440]\n [     9    212]]\n  Threshold 0.3 - F1: 0.0032, Accuracy: 0.1983, Precision: 0.0016, Recall: 0.9231\n  Confusion Matrix (Threshold 0.3):\n[[ 31523 128256]\n [    17    204]]\n  Threshold 0.4 - F1: 0.0033, Accuracy: 0.2742, Precision: 0.0016, Recall: 0.8597\n  Confusion Matrix (Threshold 0.4):\n[[ 43690 116089]\n [    31    190]]\nTraining fold 5/5\nTraining class counts:\nmaternal_mortality_risk\n0    639119\n1       881\nName: count, dtype: int64\nValidation class counts:\nmaternal_mortality_risk\n0    159779\n1       221\nName: count, dtype: int64\nChecking for NaNs in X_train before SMOTEENN for fold 5:\nGRAVIDA                      0\nPARITY                       0\nABORTIONS                    0\nHEIGHT                       0\nHEMOGLOBIN_mean              0\nHEMOGLOBIN_min               0\nHEMOGLOBIN_max               0\nWEIGHT_anc_mean              0\nWEIGHT_anc_min               0\nWEIGHT_anc_max               0\nWEIGHT_child_min             0\nsystolic_bp                  0\ndiastolic_bp                 0\nBMI                          0\nweight_gain                  0\nweight_gain_per_week         0\ngravida_parity_ratio         0\nTOTAL_ANC_VISITS             0\nNO_OF_WEEKS_max              0\nanemia_severe_systolic_bp    0\nhypertension_hemoglobin      0\nage_adolescent               0\nage_elderly                  0\nage_very_young               0\nprevious_loss                0\nrecurrent_loss               0\ninadequate_anc               0\nirregular_anc                0\nanemia_mild                  0\nanemia_moderate              0\nanemia_severe                0\never_severe_anemia           0\nhypertension                 0\nunderweight                  0\nobese                        0\nnormal_weight                0\ninadequate_weight_gain       0\nFACILITY_TYPE                0\nBLOOD_GRP                    0\nSYS_DISEASE                  0\ndtype: int64\nApplying SMOTEENN for fold 5\nPost-SMOTEENN training class counts:\nmaternal_mortality_risk\n0    631277\n1     60928\nName: count, dtype: int64\nFold 5\n  AUC: 0.6235, PR-AUC: 0.0034, Time: 8.15 seconds\n  Threshold 0.1 - F1: 0.0028, Accuracy: 0.0768, Precision: 0.0014, Recall: 0.9548\n  Confusion Matrix (Threshold 0.1):\n[[ 12079 147700]\n [    10    211]]\n  Threshold 0.2 - F1: 0.0030, Accuracy: 0.1643, Precision: 0.0015, Recall: 0.9050\n  Confusion Matrix (Threshold 0.2):\n[[ 26086 133693]\n [    21    200]]\n  Threshold 0.3 - F1: 0.0032, Accuracy: 0.2461, Precision: 0.0016, Recall: 0.8733\n  Confusion Matrix (Threshold 0.3):\n[[ 39185 120594]\n [    28    193]]\n  Threshold 0.4 - F1: 0.0033, Accuracy: 0.3219, Precision: 0.0016, Recall: 0.8009\n  Confusion Matrix (Threshold 0.4):\n[[ 51321 108458]\n [    44    177]]\n\nCross-Validation Mean Metrics:\n  AUC: 0.6303 ± 0.0197\n\nThresh 0 1:\n  F1 Score: 0.0028 ± 0.0000\n  Accuracy: 0.0562 ± 0.0241\n  Precision: 0.0014 ± 0.0000\n  Recall: 0.9782 ± 0.0178\n  PR-AUC: 0.0030 ± 0.0005\n\nThresh 0 2:\n  F1 Score: 0.0024 ± 0.0012\n  Accuracy: 0.3115 ± 0.3446\n  Precision: 0.0012 ± 0.0006\n  Recall: 0.7474 ± 0.3745\n  PR-AUC: 0.0030 ± 0.0005\n\nThresh 0 3:\n  F1 Score: 0.0025 ± 0.0013\n  Accuracy: 0.3701 ± 0.3161\n  Precision: 0.0013 ± 0.0006\n  Recall: 0.7220 ± 0.3622\n  PR-AUC: 0.0030 ± 0.0005\n\nThresh 0 4:\n  F1 Score: 0.0026 ± 0.0013\n  Accuracy: 0.4286 ± 0.2877\n  Precision: 0.0013 ± 0.0007\n  Recall: 0.6794 ± 0.3421\n  PR-AUC: 0.0030 ± 0.0005\n\nBest Model from Fold 2 with Average F1 Score: 0.0031\n\nTest Set Metrics (Best Model from Fold 2):\n  AUC: 0.6690, PR-AUC: 0.0033\n\nThreshold 0.1:\n  F1: 0.0029, Accuracy: 0.0898, Precision: 0.0015, Recall: 0.9636\n  Confusion Matrix:\n[[ 17691 182034]\n [    10    265]]\n\nThreshold 0.2:\n  F1: 0.0031, Accuracy: 0.1731, Precision: 0.0015, Recall: 0.9236\n  Confusion Matrix:\n[[ 34369 165356]\n [    21    254]]\n\nThreshold 0.3:\n  F1: 0.0033, Accuracy: 0.2511, Precision: 0.0016, Recall: 0.8945\n  Confusion Matrix:\n[[ 49974 149751]\n [    29    246]]\n\nThreshold 0.4:\n  F1: 0.0036, Accuracy: 0.3295, Precision: 0.0018, Recall: 0.8691\n  Confusion Matrix:\n[[ 65655 134070]\n [    36    239]]\n\nBest Threshold on Test Set: 0.4 with F1 Score: 0.0036\n\nPerforming SHAP analysis...\nSHAP summary plot saved as 'shap_summary_plot_maternal.png'\nSHAP feature importance bar plot saved as 'shap_importance_bar_maternal.png'\n\nSHAP Feature Importance:\n                      Feature  SHAP_Importance\n10           WEIGHT_child_min         0.950696\n36     inadequate_weight_gain         0.652248\n4             HEMOGLOBIN_mean         0.526082\n28                anemia_mild         0.470680\n38                  BLOOD_GRP         0.331091\n1                      PARITY         0.315322\n29            anemia_moderate         0.262418\n37              FACILITY_TYPE         0.256097\n18            NO_OF_WEEKS_max         0.228407\n7             WEIGHT_anc_mean         0.177749\n0                     GRAVIDA         0.147022\n3                      HEIGHT         0.140196\n13                        BMI         0.081767\n27              irregular_anc         0.078424\n35              normal_weight         0.058853\n16       gravida_parity_ratio         0.051714\n23             age_very_young         0.050535\n11                systolic_bp         0.047312\n24              previous_loss         0.039952\n12               diastolic_bp         0.022924\n2                   ABORTIONS         0.019909\n21             age_adolescent         0.019437\n33                underweight         0.017832\n34                      obese         0.004678\n25             recurrent_loss         0.003568\n32               hypertension         0.000000\n31         ever_severe_anemia         0.000000\n30              anemia_severe         0.000000\n20    hypertension_hemoglobin         0.000000\n26             inadequate_anc         0.000000\n22                age_elderly         0.000000\n19  anemia_severe_systolic_bp         0.000000\n17           TOTAL_ANC_VISITS         0.000000\n15       weight_gain_per_week         0.000000\n14                weight_gain         0.000000\n9              WEIGHT_anc_max         0.000000\n8              WEIGHT_anc_min         0.000000\n6              HEMOGLOBIN_max         0.000000\n5              HEMOGLOBIN_min         0.000000\n39                SYS_DISEASE         0.000000\n","output_type":"stream"}],"execution_count":8}]}